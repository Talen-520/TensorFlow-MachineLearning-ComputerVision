Summary:

MAE a good analytic for measuring accuracy of predictions for time series:It doesnâ€™t heavily punish larger errors like square errors do




batch size is a factor

batch gradient descent runs much faster than batch gradient descent, and is commonly used in deep learning for large datasets.



set learning rate with callback:

# Set the learning rate scheduler
lr_schedule = tf.keras.callbacks.LearningRateScheduler(
    lambda epoch: 1e-8 * 10**(epoch / 20))

# Initialize the optimizer
optimizer = tf.keras.optimizers.SGD(momentum=0.9)

# Set the training parameters
model.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer)

# Train the model
history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])


then plot graph to find proper learning rate train model again with new learning rate

# Reset states generated by Keras
tf.keras.backend.clear_session()

# Reset the weights
model.set_weights(init_weights)

learning_rate = 1e-7

# Set the optimizer
optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)

# Set the training parameters
model.compile(loss=tf.keras.losses.Huber(),
              optimizer=optimizer,
              metrics=["mae"])



for sunspot problem
windows size is 132(11 years) which is proper size,but MAE still low because theres lot of noise,
find windows size of 11 years to get much better MAE
30

Adjust batch size with nerous unit in model can imporve MAE, test